{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvAutoencoder_cassava.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNCOW27pacz2tyVP1tLzE9f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdoorash/Cassava-Disease-Classification/blob/master/Notebooks/ConvAutoencoder_cassava.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3KjymZKaOXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG7ncg8KcuI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import torch \n",
        "import torchvision \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "import pdb\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, sampler\n",
        "import imageio\n",
        "import PIL\n",
        "from IPython import display\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnMqqYUS57Cj",
        "colab_type": "code",
        "outputId": "64f845e3-f30c-4d93-8fd0-a3a814ae184b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdDkGbUl7Tf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/gdrive/My Drive/Colab Notebooks/Data/Cassava_t_v_t.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCE1bh26cuJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def show(img):\n",
        "    \"\"\"Show PyTorch tensor img as an image in matplotlib.\"\"\"\n",
        "    npimg = img.cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
        "    plt.grid(False)\n",
        "    plt.gca().axis('off')\n",
        "\n",
        "def display_thumb(img):\n",
        "  display.display(transforms.Resize(128)(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqBwTvkecuJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqlQCv5cqB68",
        "colab_type": "text"
      },
      "source": [
        "## **Prepare the dataset** (balancing, spiliting, data augmentation, ..etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eQsgmNacuJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Cassava dataset\n",
        "traindata_folder_path = '/content/ammi-2020-convnets/train/train'\n",
        "valdata_folder_path = '/content/ammi-2020-convnets/train/validation'\n",
        "testdata_folder_path = '/content/ammi-2020-convnets/test/test'\n",
        "\n",
        "\n",
        "# load the extra data for self-supervie (Autoencodrer)..\n",
        "extra_folder_path = '/content/ammi-2020-convnets/extraimages'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKHZ96aZx_jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute the mean and standard deviation of the all images (train, val, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6IhPbeBcuJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Transformations of images #################################################\n",
        "\n",
        "\n",
        "inference_transform = transforms.Compose([\n",
        "    transforms.Resize((500, 500)),\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# For visualization purposes we'll create a separate transform that operates in image space.\n",
        "inference_transform_show = transforms.Compose([\n",
        "    transforms.Resize(500),\n",
        "    transforms.CenterCrop(256),\n",
        "])\n",
        "\n",
        "\n",
        "########################################   Transform and put the data into Dataset object #########################################################################\n",
        "\n",
        "# transformed_cassava_trian = datasets.ImageFolder(traindata_folder_path, transform=inference_transform)\n",
        "# transformed_cassava_validation = datasets.ImageFolder( validdata_folder_path, transform=inference_transform) \n",
        "# transformed_cassava_test = datasets.ImageFolder(testdata_folder_path,  transform=inference_transform)\n",
        "\n",
        "# ##########################################  Load the data into DataLoader #########################################################\n",
        "# transformed_cassava_trainloader = torch.utils.data.DataLoader(transformed_cassava_train, batch_size=32, shuffle=True, num_workers=8)\n",
        "# transformed_cassava_valloader = torch.utils.data.DataLoader(transformed_cassava_val, batch_size=32, shuffle=False, num_workers=8)\n",
        "# transformed_cassava_testloader = torch.utils.data.DataLoader(transformed_cassava_test, batch_size=32, shuffle=False, num_workers=8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########## Extra data set loading ##########################################################################\n",
        "\n",
        "transformed_cassava_extra = datasets.ImageFolder(extra_folder_path, transform=inference_transform)\n",
        "transformed_cassava_extraloader = torch.utils.data.DataLoader(transformed_cassava_extra , batch_size=32, shuffle=True, num_workers=8)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNqK9cB-cuJN",
        "colab_type": "code",
        "outputId": "f242bb7e-e003-4ae5-cebe-aa6ea4006dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "transformed_cassava_extraloader.dataset.classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['extraimages']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AXc7Bm4cuJW",
        "colab_type": "code",
        "outputId": "c5c3167f-472d-4e93-ee18-0ed77bb120ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "len(train_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-250dc6d6be2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXw9HTJrqez-",
        "colab_type": "text"
      },
      "source": [
        "## **Basic function for training & testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBCBpUPinVxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_L0wGJTcuJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train (model, criterion, dataloader, optimizer, num_epochs):\n",
        "    \n",
        "    # put the model in train mode\n",
        "    model.train()\n",
        "    \n",
        "    # move the model to GPU\n",
        "    model.to(device)\n",
        "    \n",
        "\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "      print(\"Epoch {}\".format(epoch))\n",
        "      avg_loss = 0\n",
        "      correct = 0\n",
        "\n",
        "      for batch_index, (batch, target) in enumerate(dataloader):\n",
        "          batch = batch.to(device)\n",
        "          target = target.to(device)\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Forward step \n",
        "          output = model(batch)\n",
        "          loss = criterion(output.to(device), target)\n",
        "          \n",
        "          # Backward step \n",
        "          loss.backward()\n",
        "          #gradient step\n",
        "          optimizer.step()\n",
        "          \n",
        "\n",
        "          # compute the accuracy\n",
        "          prediction = output.argmax(dim=1, keepdim=True)\n",
        "          correct += prediction.cpu().eq(target.cpu().view_as(prediction)).sum().item()\n",
        "\n",
        "          # avarge of loss\n",
        "          avg_loss += loss.item()\n",
        "          # print(\"Loss : {}\".format(loss.item()))\n",
        "\n",
        "      # losses.append(avg_loss/len(batch))    \n",
        "      percent = 100. * correct / len(dataloader.dataset)\n",
        "      # Print out progress the end of epoch.\n",
        "      print('Train Epoch: {} \\tLoss: {:.6f} \\t Accuracy: {:.2f}%'.format(\n",
        "              epoch, avg_loss/len(batch), percent)\n",
        "        )\n",
        "\n",
        "def test (model, criterion, dataloader):\n",
        "    \n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    # avg_loss = 0\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for data, target in dataloader:\n",
        "             \n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            \n",
        "            output = model(data).to(device)\n",
        "            loss = criterion(output, target) \n",
        "            \n",
        "            prediction = output.argmax(dim=1, keepdim=True) \n",
        "            correct += prediction.cpu().eq(target.view_as(prediction)).sum().item()\n",
        "            \n",
        "            # avg_loss += loss.item() \n",
        "    percent = 100. * correct / len(dataloader.dataset)\n",
        "    print(f'Accuracy: {correct}/{len(dataloader.dataset)} ({percent:.0f}%)')\n",
        "   \n",
        "    return percent  \n",
        "    \n",
        "    \n",
        "    \n",
        "        \n",
        "        \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ckvO2lm9fdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_auto (model, criterion, dataloader, optimizer, num_epochs):\n",
        "    \n",
        "    # put the model in train mode\n",
        "    model.train()\n",
        "    \n",
        "    # move the model to GPU\n",
        "    model.to(device)\n",
        "    \n",
        "\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "      print(\"Epoch {}\".format(epoch))\n",
        "      avg_loss = 0\n",
        "      correct = 0\n",
        "\n",
        "      for batch_index, (batch, _) in enumerate(dataloader):\n",
        "          batch = batch.to(device)\n",
        "          \n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Forward step \n",
        "          output = model(batch)\n",
        "          loss = criterion(output.to(device), batch)\n",
        "          \n",
        "          # Backward step \n",
        "          loss.backward()\n",
        "          #gradient step\n",
        "          optimizer.step()\n",
        "          \n",
        "\n",
        "          # compute the accuracy\n",
        "          prediction = output.argmax(dim=1, keepdim=True)\n",
        "          correct += prediction.cpu().eq(target.cpu().view_as(prediction)).sum().item()\n",
        "\n",
        "          # avarge of loss\n",
        "          avg_loss += loss.item()\n",
        "          # print(\"Loss : {}\".format(loss.item()))\n",
        "\n",
        "      # losses.append(avg_loss/len(batch))    \n",
        "      percent = 100. * correct / len(dataloader.dataset)\n",
        "      # Print out progress the end of epoch.\n",
        "      print('Train Epoch: {} \\tLoss: {:.6f} \\t Accuracy: {:.2f}%'.format(\n",
        "              epoch, avg_loss/len(batch), percent)\n",
        "        )\n",
        "\n",
        "def test_auto (model, criterion, dataloader):\n",
        "    \n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    # avg_loss = 0\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for data, target in dataloader:\n",
        "             \n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            \n",
        "            output = model(data).to(device)\n",
        "            loss = criterion(output, target) \n",
        "            \n",
        "            prediction = output.argmax(dim=1, keepdim=True) \n",
        "            correct += prediction.cpu().eq(target.view_as(prediction)).sum().item()\n",
        "            \n",
        "            # avg_loss += loss.item() \n",
        "    percent = 100. * correct / len(dataloader.dataset)\n",
        "    print(f'Accuracy: {correct}/{len(dataloader.dataset)} ({percent:.0f}%)')\n",
        "   \n",
        "    return percent  \n",
        "    \n",
        "    \n",
        "    \n",
        "        \n",
        "        \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3mtjucTqtTK",
        "colab_type": "text"
      },
      "source": [
        "## **Model Architecture (CNN+Decoder)** \n",
        "Train the CNN on the unlabel data to learn the featuers, then train it on the prepared train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyqeTZJel-uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNNModel, self).__init__()\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
        "        nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
        "        nn.MaxPool2d(3),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "    self.block2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "        nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "        nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "    )\n",
        "    \n",
        "  \n",
        "\n",
        " \n",
        "    self.avpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "    # self.fc  =  nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.block1(x)\n",
        "      x = self.block2(x)\n",
        "    \n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHu_kPeXoEJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvAutoencoder(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(ConvAutoencoder, self).__init__()\n",
        "      ## encoder layers ##\n",
        "      \n",
        "      self.encoder = CNNModel()\n",
        "      \n",
        "      ## decoder layers ##\n",
        "      self.decoder = nn.Sequential(\n",
        "          nn.Conv2d(32,  8, kernel_size=3, stride=1),\n",
        "          nn.UpsamplingNearest2d(180),\n",
        "          nn.Conv2d(8, 3, 3),\n",
        "          nn.UpsamplingNearest2d(256),\n",
        "      )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      ## encode ##\n",
        "      x = self.encoder(x)\n",
        "      \n",
        "\n",
        "      ## decode ##\n",
        "      x = self.decoder(x)\n",
        "              \n",
        "      return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3io_6w0Q_Dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Architectuer..\n",
        "modelCNN = CNNModel()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-wHxkFMzkqI",
        "colab_type": "code",
        "outputId": "de2d3842-0278-4cad-a002-69014060564d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sum(p.numel() for p in convAout.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26163"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JraLkybtrSZV",
        "colab_type": "text"
      },
      "source": [
        "## **Run the Model**  (checkpoint save and load, optimizer,...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25tAGkCiliZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ConvAutoencoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpy6aZCc4uI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/gdrive/My Drive/Colab Notebooks/model_data_checkpoints/a284\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWhFLbjOIdOD",
        "colab_type": "code",
        "outputId": "0c6bac19-2533-4c5a-fb7f-25c4e697181e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "# load the checkpoint...\n",
        "model = model.load_state_dict(torch.load(\"/content/gdrive/My Drive/Colab Notebooks/model_data_checkpoints/a284\"))\n",
        "# model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-b3db77e655c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/Colab Notebooks/model_data_checkpoints/a284\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab Notebooks/model_data_checkpoints/a284'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKN-mMnJcuKO",
        "colab_type": "code",
        "outputId": "1d9cbe49-866c-4434-e414-1c896c1e4531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "if device == 'cuda':\n",
        "    model = model.cuda()\n",
        "    \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "train_auto(model, nn.MSELoss(), transformed_imagenet_loader, optimizer, 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-90d732544b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_auto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_imagenet_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'transformed_imagenet_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww1Q2NjB4RzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}