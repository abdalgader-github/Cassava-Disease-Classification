{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "ResNet_Pretrained_cassava.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdoorash/Cassava-Disease-Classification/blob/master/Notebooks/ResNet_Pretrained_cassava.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2fpuissLorQ",
        "colab_type": "text"
      },
      "source": [
        "## **ResNet_Pretrained Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG7ncg8KcuI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import torch \n",
        "import torchvision \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "import pdb\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, sampler\n",
        "import imageio\n",
        "import PIL\n",
        "from IPython import display\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnMqqYUS57Cj",
        "colab_type": "code",
        "outputId": "704c85e1-a808-497a-c035-e051c15aee56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN8dNtWU8RO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/gdrive/My Drive/Colab Notebooks/Data/Cassava_t_v_t.zip\";"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCE1bh26cuJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def show(img):\n",
        "    \"\"\"Show PyTorch tensor img as an image in matplotlib.\"\"\"\n",
        "    npimg = img.cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
        "    plt.grid(False)\n",
        "    plt.gca().axis('off')\n",
        "\n",
        "def display_thumb(img):\n",
        "  display.display(transforms.Resize(128)(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqBwTvkecuJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqlQCv5cqB68",
        "colab_type": "text"
      },
      "source": [
        "## **Prepare the dataset** (balancing, spiliting, data augmentation, ..etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eQsgmNacuJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Cassava dataset\n",
        "traindata_folder_path = '/content/ammi-2020-convnets/train/train'\n",
        "valdata_folder_path = '/content/ammi-2020-convnets/train/validation'\n",
        "testdata_folder_path = '/content/ammi-2020-convnets/test/test'\n",
        "\n",
        "\n",
        "# load the extra data for self-supervie (Autoencodrer)..\n",
        "extra_folder_path = '/content/ammi-2020-convnets/extraimages'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKHZ96aZx_jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute the mean and standard deviation of the all images (train, val, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htAT-qp3-cxJ",
        "colab_type": "code",
        "outputId": "246b53d3-364d-4e11-ee12-23e0626d1ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# torch_example = torch.randn((100, 3, 50, 50))\n",
        "# torch_example_mean = torch_example.mean(axis=(0,2,3))\n",
        "# torch_example_mean\n",
        "# # torch_example_mean2 = torch_example.mean(axis=(2,3))\n",
        "# print('per batch = {0}'.format(torch_example_mean2.shape))\n",
        "# torch_example_mean2 = torch_example_mean2.mean(axis=(0))\n",
        "# print('per batch_and h and w = {0}'.format(torch_example_mean2.shape))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0001, -0.0008, -0.0002])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8brTFpi_DlJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf = transforms.Compose([\n",
        "#     transforms.Resize((256, 256)),\n",
        "#     transforms.ToTensor(),\n",
        "# ])\n",
        "# cassava_train = datasets.ImageFolder(traindata_folder_path, transform=tf)\n",
        "# trainloader = torch.utils.data.DataLoader(cassava_train, batch_size=700, shuffle=True, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q864XxsqAlze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # compute the mean and standard deviation of the images ...\n",
        "# run_mean = torch.zeros(3)\n",
        "# for i, (batch,_) in enumerate(trainloader):\n",
        "#   curr_mean = batch.mean(axis=(0,2,3))\n",
        "#   run_mean = ((run_mean*i) + curr_mean)/(i+1) \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmhSHsLCI5Q7",
        "colab_type": "code",
        "outputId": "7becbee7-d38a-47ff-d248-06cfddef2ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# run_mean "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4479, 0.4963, 0.3217])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hspMPAmZLLTf",
        "colab_type": "code",
        "outputId": "f6416c6a-afd4-4c42-d237-63f2d12fe865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "# for imgs,_ in trainloader:\n",
        "#     print(imgs.std((0,2,3)))\n",
        "#     break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2074, 0.2087, 0.1896])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6IhPbeBcuJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Transformations of images #################################################\n",
        "\n",
        "\n",
        "inference_transform = transforms.Compose([\n",
        "    transforms.Resize((500, 500)),\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4479, 0.4963, 0.3217], [0.2074, 0.2087, 0.1896])\n",
        "])\n",
        "\n",
        "# For visualization purposes we'll create a separate transform that operates in image space.\n",
        "inference_transform_show = transforms.Compose([\n",
        "    transforms.Resize(500),\n",
        "    transforms.CenterCrop(256),\n",
        "])\n",
        "\n",
        "\n",
        "########################################   Transform and put the data into Dataset object #########################################################################\n",
        "\n",
        "transformed_cassava_trian = datasets.ImageFolder(traindata_folder_path, transform=inference_transform)\n",
        "transformed_cassava_validation = datasets.ImageFolder( valdata_folder_path, transform=inference_transform) \n",
        "transformed_cassava_test = datasets.ImageFolder(testdata_folder_path,  transform=inference_transform)\n",
        "\n",
        "##########################################  Load the data into DataLoader #########################################################\n",
        "transformed_cassava_trainloader = torch.utils.data.DataLoader(transformed_cassava_trian, batch_size=32, shuffle=True, num_workers=8)\n",
        "transformed_cassava_valloader = torch.utils.data.DataLoader(transformed_cassava_validation, batch_size=32, shuffle=False, num_workers=8)\n",
        "transformed_cassava_testloader = torch.utils.data.DataLoader(transformed_cassava_test, batch_size=32, shuffle=False, num_workers=8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########## Extra data set loading ##########################################################################\n",
        "\n",
        "transformed_cassava_extra = datasets.ImageFolder(extra_folder_path, transform=inference_transform)\n",
        "transformed_cassava_extraloader = torch.utils.data.DataLoader(transformed_cassava_extra , batch_size=32, shuffle=True, num_workers=8)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXw9HTJrqez-",
        "colab_type": "text"
      },
      "source": [
        "## **Basic function for training & testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBCBpUPinVxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_L0wGJTcuJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "def train (model, criterion, train_dataloader, valid_dataloader, optimizer, num_epochs):\n",
        "    \n",
        "    \n",
        "    \n",
        "    # move the model to GPU\n",
        "    model.to(device)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"# Start training...\")\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "      train_loss = 0\n",
        "      train_n_iter = 0\n",
        "      tcorrect = 0\n",
        "\n",
        "      # put the model in train mode\n",
        "      model.train()\n",
        "     \n",
        "      for batch_index, (batch, target) in enumerate(train_dataloader):\n",
        "          batch = batch.to(device)\n",
        "          target = target.to(device)\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          \n",
        "          # Forward step \n",
        "          output = model(batch)\n",
        "          loss = criterion(output.to(device), target)\n",
        "          \n",
        "          # Backward step \n",
        "          loss.backward()\n",
        "          #gradient step\n",
        "          optimizer.step()\n",
        "          \n",
        "\n",
        "          # compute the accuracy\n",
        "          prediction = output.argmax(dim=1, keepdim=True)\n",
        "          tcorrect += prediction.cpu().eq(target.cpu().view_as(prediction)).sum().item()\n",
        "\n",
        "          # avarge of loss\n",
        "          train_loss += loss.item()\n",
        "          train_n_iter += 1\n",
        "\n",
        "      valid_loss = 0\n",
        "      valid_n_iter = 0\n",
        "      vcorrect = 0\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      #iterate over valid data..\n",
        "      for images, labels in transformed_cassava_valloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        #forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # compute accuracy\n",
        "        prediction = outputs.argmax(dim=1, keepdim=True)\n",
        "        vcorrect += prediction.cpu().eq(labels.cpu().view_as(prediction)).sum().item()\n",
        "        \n",
        "        # loss and accuracy\n",
        "        valid_loss += loss.item()\n",
        "        valid_n_iter += 1\n",
        "\n",
        "      \n",
        "      train_losses.append(train_loss/train_n_iter)\n",
        "      valid_losses.append(valid_loss/valid_n_iter)\n",
        "   \n",
        "      train_percent = 100. * tcorrect / len(train_dataloader.dataset)\n",
        "      valid_percent = 100. * vcorrect / len(valid_dataloader.dataset) \n",
        "\n",
        "      # Print out progress the end of epoch.\n",
        "      print('\\nEpoch:{}/{} \\tTrain Loss: {:.4f} \\tValid Loss: {:.4f} -------- Train Accuracy: {} \\tValid Accuracy: {}\\tDF: {}'.format(\n",
        "         epoch + 1, num_epochs,\n",
        "        train_loss/train_n_iter, valid_loss / valid_n_iter,\n",
        "        train_percent, valid_percent, train_percent-valid_percent))\n",
        "\n",
        "def test (model, criterion, dataloader):\n",
        "    \n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    # avg_loss = 0\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for data, target in dataloader:\n",
        "             \n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            \n",
        "            output = model(data).to(device)\n",
        "            loss = criterion(output, target) \n",
        "            \n",
        "            prediction = output.argmax(dim=1, keepdim=True) \n",
        "            correct += prediction.cpu().eq(target.view_as(prediction)).sum().item()\n",
        "            \n",
        "            # avg_loss += loss.item() \n",
        "    percent = 100. * correct / len(dataloader.dataset)\n",
        "    print(f'Accuracy: {correct}/{len(dataloader.dataset)} ({percent:.0f}%)')\n",
        "   \n",
        "    return percent  \n",
        "    \n",
        "    \n",
        "    \n",
        "        \n",
        "        \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ckvO2lm9fdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3mtjucTqtTK",
        "colab_type": "text"
      },
      "source": [
        "## **Model Architecture (ResNet)** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "MEdBON8HcuJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83aae316-7aa2-46fb-ebcd-38bc2c86b527"
      },
      "source": [
        "# define the per-trained model...\n",
        "full_resnet_model = torchvision.models.resnet18(pretrained=True)\n",
        "full_resnet_model"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyqeTZJel-uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelResNet(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(ModelResNet, self).__init__()\n",
        "    self.res_mod = nn.Sequential(*list(full_resnet_model.children())[:-5])\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.fc =  nn.Linear(64, 5)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.res_mod(x)\n",
        "      x = self.avgpool(x)\n",
        "      x = self.fc(x.view(x.size(0), -1))\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3io_6w0Q_Dm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "8e34f8a5-f11f-4ee9-b9ea-a5b59c091337"
      },
      "source": [
        "# Model Architectuer..\n",
        "model = ModelResNet()\n",
        "model"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelResNet(\n",
              "  (res_mod): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JraLkybtrSZV",
        "colab_type": "text"
      },
      "source": [
        "## **Run the Model**  (checkpoint save and load, optimizer,...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25tAGkCiliZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create checkpoint ...\n",
        "path = \"/content/gdrive/My Drive/Colab Notebooks/model_data_checkpoints/ResNet/resnetcp_1.pt\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWhFLbjOIdOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the checkpoint...\n",
        "# model = model.load_state_dict(torch.load(\"/content/gdrive/My Drive/Colab Notebooks/model_data_checkpoints/ResNet/resnetcp_1.pt\"))\n",
        "# model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKN-mMnJcuKO",
        "colab_type": "code",
        "outputId": "becb01d0-1889-4af6-8abf-43414a5e9eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if device == 'cuda':\n",
        "    model = model.cuda()\n",
        "num_epochs = 100   \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "train(model, nn.CrossEntropyLoss(), transformed_cassava_trainloader,  transformed_cassava_valloader, optimizer, num_epochs)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Start training...\n",
            "\n",
            "Epoch:1/100 \tTrain Loss: 1.1133 \tValid Loss: 1.7727 -------- Train Accuracy: 60.32639279684862 \tValid Accuracy: 36.30769230769231\n",
            "\n",
            "Epoch:2/100 \tTrain Loss: 1.0497 \tValid Loss: 1.7286 -------- Train Accuracy: 62.16469705496154 \tValid Accuracy: 36.61538461538461\n",
            "\n",
            "Epoch:3/100 \tTrain Loss: 1.0282 \tValid Loss: 1.7875 -------- Train Accuracy: 63.44025511161133 \tValid Accuracy: 35.69230769230769\n",
            "\n",
            "Epoch:4/100 \tTrain Loss: 1.0081 \tValid Loss: 1.8721 -------- Train Accuracy: 63.98424310635903 \tValid Accuracy: 33.53846153846154\n",
            "\n",
            "Epoch:5/100 \tTrain Loss: 0.9888 \tValid Loss: 1.7257 -------- Train Accuracy: 64.30313262052148 \tValid Accuracy: 40.30769230769231\n",
            "\n",
            "Epoch:6/100 \tTrain Loss: 0.9840 \tValid Loss: 1.4978 -------- Train Accuracy: 65.01594447570812 \tValid Accuracy: 40.61538461538461\n",
            "\n",
            "Epoch:7/100 \tTrain Loss: 0.9689 \tValid Loss: 2.3509 -------- Train Accuracy: 64.75332958169199 \tValid Accuracy: 36.30769230769231\n",
            "\n",
            "Epoch:8/100 \tTrain Loss: 0.9501 \tValid Loss: 1.4499 -------- Train Accuracy: 64.84712061526918 \tValid Accuracy: 39.07692307692308\n",
            "\n",
            "Epoch:9/100 \tTrain Loss: 0.9225 \tValid Loss: 1.5396 -------- Train Accuracy: 66.10392046520353 \tValid Accuracy: 39.07692307692308\n",
            "\n",
            "Epoch:10/100 \tTrain Loss: 0.8911 \tValid Loss: 1.2525 -------- Train Accuracy: 67.51078596886137 \tValid Accuracy: 49.23076923076923\n",
            "\n",
            "Epoch:11/100 \tTrain Loss: 0.8715 \tValid Loss: 1.5521 -------- Train Accuracy: 67.90470830988558 \tValid Accuracy: 44.0\n",
            "\n",
            "Epoch:12/100 \tTrain Loss: 0.8536 \tValid Loss: 1.2382 -------- Train Accuracy: 68.67379478521853 \tValid Accuracy: 48.92307692307692\n",
            "\n",
            "Epoch:13/100 \tTrain Loss: 0.8309 \tValid Loss: 1.2021 -------- Train Accuracy: 69.38660664040518 \tValid Accuracy: 52.92307692307692\n",
            "\n",
            "Epoch:14/100 \tTrain Loss: 0.8180 \tValid Loss: 1.8340 -------- Train Accuracy: 70.75595573063215 \tValid Accuracy: 41.84615384615385\n",
            "\n",
            "Epoch:15/100 \tTrain Loss: 0.7785 \tValid Loss: 1.1758 -------- Train Accuracy: 72.4066779215907 \tValid Accuracy: 54.46153846153846\n",
            "\n",
            "Epoch:16/100 \tTrain Loss: 0.7507 \tValid Loss: 1.3326 -------- Train Accuracy: 72.98818232976927 \tValid Accuracy: 54.15384615384615\n",
            "\n",
            "Epoch:17/100 \tTrain Loss: 0.7226 \tValid Loss: 1.5040 -------- Train Accuracy: 74.05740011254925 \tValid Accuracy: 51.07692307692308\n",
            "\n",
            "Epoch:18/100 \tTrain Loss: 0.7285 \tValid Loss: 1.2139 -------- Train Accuracy: 74.84524479459763 \tValid Accuracy: 56.61538461538461\n",
            "\n",
            "Epoch:19/100 \tTrain Loss: 0.6922 \tValid Loss: 1.3398 -------- Train Accuracy: 75.57681485649972 \tValid Accuracy: 51.07692307692308\n",
            "\n",
            "Epoch:20/100 \tTrain Loss: 0.6848 \tValid Loss: 1.0714 -------- Train Accuracy: 75.59557306321516 \tValid Accuracy: 58.76923076923077\n",
            "\n",
            "Epoch:21/100 \tTrain Loss: 0.6497 \tValid Loss: 1.1438 -------- Train Accuracy: 77.20877884074282 \tValid Accuracy: 61.53846153846154\n",
            "\n",
            "Epoch:22/100 \tTrain Loss: 0.6450 \tValid Loss: 0.9764 -------- Train Accuracy: 77.15250422059651 \tValid Accuracy: 62.76923076923077\n",
            "\n",
            "Epoch:23/100 \tTrain Loss: 0.6135 \tValid Loss: 1.3172 -------- Train Accuracy: 77.71525042205965 \tValid Accuracy: 62.15384615384615\n",
            "\n",
            "Epoch:24/100 \tTrain Loss: 0.6036 \tValid Loss: 1.0375 -------- Train Accuracy: 79.23466516601013 \tValid Accuracy: 60.92307692307692\n",
            "\n",
            "Epoch:25/100 \tTrain Loss: 0.5886 \tValid Loss: 0.9132 -------- Train Accuracy: 79.38473081973363 \tValid Accuracy: 66.46153846153847\n",
            "\n",
            "Epoch:26/100 \tTrain Loss: 0.5860 \tValid Loss: 1.5135 -------- Train Accuracy: 79.34721440630275 \tValid Accuracy: 44.61538461538461\n",
            "\n",
            "Epoch:27/100 \tTrain Loss: 0.5744 \tValid Loss: 1.1826 -------- Train Accuracy: 80.00375164134309 \tValid Accuracy: 59.69230769230769\n",
            "\n",
            "Epoch:28/100 \tTrain Loss: 0.5499 \tValid Loss: 1.0734 -------- Train Accuracy: 80.58525604952166 \tValid Accuracy: 63.38461538461539\n",
            "\n",
            "Epoch:29/100 \tTrain Loss: 0.5538 \tValid Loss: 0.9979 -------- Train Accuracy: 80.19133370849747 \tValid Accuracy: 61.84615384615385\n",
            "\n",
            "Epoch:30/100 \tTrain Loss: 0.5448 \tValid Loss: 0.9145 -------- Train Accuracy: 80.81035453010692 \tValid Accuracy: 64.61538461538461\n",
            "\n",
            "Epoch:31/100 \tTrain Loss: 0.5177 \tValid Loss: 1.2388 -------- Train Accuracy: 82.21722003376478 \tValid Accuracy: 61.53846153846154\n",
            "\n",
            "Epoch:32/100 \tTrain Loss: 0.5100 \tValid Loss: 1.2229 -------- Train Accuracy: 82.31101106734197 \tValid Accuracy: 61.23076923076923\n",
            "\n",
            "Epoch:33/100 \tTrain Loss: 0.5085 \tValid Loss: 1.0043 -------- Train Accuracy: 82.64865878821985 \tValid Accuracy: 60.30769230769231\n",
            "\n",
            "Epoch:34/100 \tTrain Loss: 0.4897 \tValid Loss: 0.9776 -------- Train Accuracy: 82.1797036203339 \tValid Accuracy: 64.61538461538461\n",
            "\n",
            "Epoch:35/100 \tTrain Loss: 0.4784 \tValid Loss: 0.9195 -------- Train Accuracy: 83.45526167698368 \tValid Accuracy: 66.76923076923077\n",
            "\n",
            "Epoch:36/100 \tTrain Loss: 0.4732 \tValid Loss: 0.8600 -------- Train Accuracy: 83.60532733070718 \tValid Accuracy: 68.0\n",
            "\n",
            "Epoch:37/100 \tTrain Loss: 0.4657 \tValid Loss: 0.9855 -------- Train Accuracy: 83.5678109172763 \tValid Accuracy: 64.61538461538461\n",
            "\n",
            "Epoch:38/100 \tTrain Loss: 0.4532 \tValid Loss: 1.2920 -------- Train Accuracy: 84.01800787844682 \tValid Accuracy: 61.84615384615385\n",
            "\n",
            "Epoch:39/100 \tTrain Loss: 0.4481 \tValid Loss: 0.9428 -------- Train Accuracy: 84.50572125304821 \tValid Accuracy: 65.84615384615384\n",
            "\n",
            "Epoch:41/100 \tTrain Loss: 0.4128 \tValid Loss: 1.7447 -------- Train Accuracy: 84.69330332020259 \tValid Accuracy: 50.46153846153846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "Process Process-880:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-82-d4c3618c3f6e>\", line 5, in <module>\n",
            "    train(model, nn.CrossEntropyLoss(), transformed_cassava_trainloader,  transformed_cassava_valloader, optimizer, num_epochs)\n",
            "  File \"<ipython-input-58-b9daa66e84a3>\", line 24, in train\n",
            "    for batch_index, (batch, target) in enumerate(train_dataloader):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 841, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 808, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 761, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.6/selectors.py\", line 376, in select\n",
            "    fd_event_list = self._poll.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eg_B6clax0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3bfa5663-1d97-4e9b-b106-e8ce52942f77"
      },
      "source": [
        "# Save history for later\n",
        "train_loss_history = train_losses\n",
        "valid_loss_history = valid_losses\n",
        "\n",
        "# Plot training and validation curve\n",
        "x = range(1, num_epochs + 1)\n",
        "plt.plot(x, train_loss_history, label='train')\n",
        "plt.plot(x, valid_loss_history, label='valid')\n",
        "\n",
        "plt.xlabel('# epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-4977bddf1358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot training and validation curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfQjlpWbguBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}